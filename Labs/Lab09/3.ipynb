{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6698646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadd484d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'quality',\n",
       " 'Id']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Me\\Desktop\\LabFinals\\WineQT.csv')\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f27296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1138            6.3             0.510         0.13             2.3      0.076   \n",
       "1139            6.8             0.620         0.08             1.9      0.068   \n",
       "1140            6.2             0.600         0.08             2.0      0.090   \n",
       "1141            5.9             0.550         0.10             2.2      0.062   \n",
       "1142            5.9             0.645         0.12             2.0      0.075   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1138     11.0        6  \n",
       "1139      9.5        6  \n",
       "1140     10.5        5  \n",
       "1141     11.2        6  \n",
       "1142     10.2        5  \n",
       "\n",
       "[1143 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec1d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'] = df['quality'].apply(lambda x:1 if x>=6 else 0 )\n",
    "\n",
    "X = df.drop('quality',axis=1)\n",
    "y = df['quality']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527a2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566896b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2f4ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Me\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7013 - loss: 0.5934 - precision: 0.6949 - recall: 0.7976 - val_accuracy: 0.7118 - val_loss: 0.5389 - val_precision: 0.7699 - val_recall: 0.6850\n",
      "Epoch 2/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7462 - loss: 0.5181 - precision: 0.8005 - recall: 0.7065 - val_accuracy: 0.7555 - val_loss: 0.5239 - val_precision: 0.7710 - val_recall: 0.7953\n",
      "Epoch 3/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7735 - loss: 0.5008 - precision: 0.8047 - recall: 0.7672 - val_accuracy: 0.7467 - val_loss: 0.5294 - val_precision: 0.7805 - val_recall: 0.7559\n",
      "Epoch 4/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7615 - loss: 0.4885 - precision: 0.8053 - recall: 0.7368 - val_accuracy: 0.7380 - val_loss: 0.5177 - val_precision: 0.7557 - val_recall: 0.7795\n",
      "Epoch 5/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7659 - loss: 0.4768 - precision: 0.8030 - recall: 0.7510 - val_accuracy: 0.7205 - val_loss: 0.5230 - val_precision: 0.7647 - val_recall: 0.7165\n",
      "Epoch 6/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.4657 - precision: 0.8051 - recall: 0.7692 - val_accuracy: 0.7424 - val_loss: 0.5136 - val_precision: 0.7615 - val_recall: 0.7795\n",
      "Epoch 7/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7845 - loss: 0.4570 - precision: 0.8207 - recall: 0.7692 - val_accuracy: 0.7249 - val_loss: 0.5071 - val_precision: 0.7581 - val_recall: 0.7402\n",
      "Epoch 8/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7856 - loss: 0.4571 - precision: 0.8157 - recall: 0.7794 - val_accuracy: 0.7205 - val_loss: 0.5089 - val_precision: 0.7603 - val_recall: 0.7244\n",
      "Epoch 9/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.4415 - precision: 0.8235 - recall: 0.7935 - val_accuracy: 0.7205 - val_loss: 0.5121 - val_precision: 0.7603 - val_recall: 0.7244\n",
      "Epoch 10/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7921 - loss: 0.4340 - precision: 0.8234 - recall: 0.7834 - val_accuracy: 0.7162 - val_loss: 0.5089 - val_precision: 0.7500 - val_recall: 0.7323\n",
      "Epoch 11/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4264 - precision: 0.8218 - recall: 0.7935 - val_accuracy: 0.7380 - val_loss: 0.5087 - val_precision: 0.7638 - val_recall: 0.7638\n",
      "Epoch 12/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8107 - loss: 0.4207 - precision: 0.8467 - recall: 0.7935 - val_accuracy: 0.7336 - val_loss: 0.5116 - val_precision: 0.7619 - val_recall: 0.7559\n",
      "Epoch 13/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4100 - precision: 0.8412 - recall: 0.7935 - val_accuracy: 0.7205 - val_loss: 0.5155 - val_precision: 0.7520 - val_recall: 0.7402\n",
      "Epoch 14/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.4068 - precision: 0.8400 - recall: 0.8077 - val_accuracy: 0.7249 - val_loss: 0.5153 - val_precision: 0.7581 - val_recall: 0.7402\n",
      "Epoch 15/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8260 - loss: 0.4020 - precision: 0.8439 - recall: 0.8320 - val_accuracy: 0.7336 - val_loss: 0.5295 - val_precision: 0.7578 - val_recall: 0.7638\n",
      "Epoch 16/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.3906 - precision: 0.8353 - recall: 0.8421 - val_accuracy: 0.7424 - val_loss: 0.5385 - val_precision: 0.7931 - val_recall: 0.7244\n",
      "Epoch 17/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.3892 - precision: 0.8485 - recall: 0.8279 - val_accuracy: 0.7249 - val_loss: 0.5226 - val_precision: 0.7623 - val_recall: 0.7323\n",
      "Epoch 18/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8260 - loss: 0.3892 - precision: 0.8454 - recall: 0.8300 - val_accuracy: 0.7380 - val_loss: 0.5413 - val_precision: 0.8018 - val_recall: 0.7008\n",
      "Epoch 19/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8326 - loss: 0.3788 - precision: 0.8589 - recall: 0.8259 - val_accuracy: 0.7336 - val_loss: 0.5358 - val_precision: 0.7391 - val_recall: 0.8031\n",
      "Epoch 20/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.3715 - precision: 0.8519 - recall: 0.8502 - val_accuracy: 0.7467 - val_loss: 0.5366 - val_precision: 0.7949 - val_recall: 0.7323\n",
      "Epoch 21/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 0.3597 - precision: 0.8483 - recall: 0.8603 - val_accuracy: 0.7642 - val_loss: 0.5427 - val_precision: 0.8017 - val_recall: 0.7638\n",
      "Epoch 22/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8567 - loss: 0.3556 - precision: 0.8682 - recall: 0.8664 - val_accuracy: 0.7249 - val_loss: 0.5404 - val_precision: 0.7286 - val_recall: 0.8031\n",
      "Epoch 23/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.3465 - precision: 0.8617 - recall: 0.8704 - val_accuracy: 0.7598 - val_loss: 0.5302 - val_precision: 0.7769 - val_recall: 0.7953\n",
      "Epoch 24/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.3441 - precision: 0.8463 - recall: 0.8583 - val_accuracy: 0.7467 - val_loss: 0.5612 - val_precision: 0.7851 - val_recall: 0.7480\n",
      "Epoch 25/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8479 - loss: 0.3440 - precision: 0.8615 - recall: 0.8563 - val_accuracy: 0.7598 - val_loss: 0.5411 - val_precision: 0.7951 - val_recall: 0.7638\n",
      "Epoch 26/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8589 - loss: 0.3308 - precision: 0.8657 - recall: 0.8745 - val_accuracy: 0.7555 - val_loss: 0.5801 - val_precision: 0.8318 - val_recall: 0.7008\n",
      "Epoch 27/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 0.3322 - precision: 0.8660 - recall: 0.8765 - val_accuracy: 0.7424 - val_loss: 0.5530 - val_precision: 0.7464 - val_recall: 0.8110\n",
      "Epoch 28/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.3165 - precision: 0.8593 - recall: 0.9028 - val_accuracy: 0.7642 - val_loss: 0.5779 - val_precision: 0.8120 - val_recall: 0.7480\n",
      "Epoch 29/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8709 - loss: 0.3095 - precision: 0.8806 - recall: 0.8806 - val_accuracy: 0.7380 - val_loss: 0.5615 - val_precision: 0.7445 - val_recall: 0.8031\n",
      "Epoch 30/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8709 - loss: 0.3078 - precision: 0.8715 - recall: 0.8927 - val_accuracy: 0.7555 - val_loss: 0.5923 - val_precision: 0.7710 - val_recall: 0.7953\n",
      "Epoch 31/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8753 - loss: 0.3006 - precision: 0.8909 - recall: 0.8765 - val_accuracy: 0.7511 - val_loss: 0.5756 - val_precision: 0.7612 - val_recall: 0.8031\n",
      "Epoch 32/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8764 - loss: 0.3053 - precision: 0.8671 - recall: 0.9109 - val_accuracy: 0.7424 - val_loss: 0.6046 - val_precision: 0.7500 - val_recall: 0.8031\n",
      "Epoch 33/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8731 - loss: 0.2886 - precision: 0.8765 - recall: 0.8907 - val_accuracy: 0.7336 - val_loss: 0.5945 - val_precision: 0.7463 - val_recall: 0.7874\n",
      "Epoch 34/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8928 - loss: 0.2830 - precision: 0.8852 - recall: 0.9211 - val_accuracy: 0.7511 - val_loss: 0.6200 - val_precision: 0.7823 - val_recall: 0.7638\n",
      "Epoch 35/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8873 - loss: 0.2747 - precision: 0.8887 - recall: 0.9049 - val_accuracy: 0.7555 - val_loss: 0.6120 - val_precision: 0.7840 - val_recall: 0.7717\n",
      "Epoch 36/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8884 - loss: 0.2743 - precision: 0.8920 - recall: 0.9028 - val_accuracy: 0.7511 - val_loss: 0.5985 - val_precision: 0.7574 - val_recall: 0.8110\n",
      "Epoch 37/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8928 - loss: 0.2594 - precision: 0.8837 - recall: 0.9231 - val_accuracy: 0.7293 - val_loss: 0.6477 - val_precision: 0.7519 - val_recall: 0.7638\n",
      "Epoch 38/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9070 - loss: 0.2537 - precision: 0.9082 - recall: 0.9211 - val_accuracy: 0.7424 - val_loss: 0.6292 - val_precision: 0.7787 - val_recall: 0.7480\n",
      "Epoch 39/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8917 - loss: 0.2567 - precision: 0.8958 - recall: 0.9049 - val_accuracy: 0.7686 - val_loss: 0.6504 - val_precision: 0.7681 - val_recall: 0.8346\n",
      "Epoch 40/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.2535 - precision: 0.8976 - recall: 0.9231 - val_accuracy: 0.7686 - val_loss: 0.6052 - val_precision: 0.7937 - val_recall: 0.7874\n",
      "Epoch 41/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8939 - loss: 0.2459 - precision: 0.8994 - recall: 0.9049 - val_accuracy: 0.7424 - val_loss: 0.6833 - val_precision: 0.7656 - val_recall: 0.7717\n",
      "Epoch 42/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8993 - loss: 0.2399 - precision: 0.8941 - recall: 0.9231 - val_accuracy: 0.7424 - val_loss: 0.6749 - val_precision: 0.7833 - val_recall: 0.7402\n",
      "Epoch 43/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9103 - loss: 0.2279 - precision: 0.9137 - recall: 0.9211 - val_accuracy: 0.7424 - val_loss: 0.6773 - val_precision: 0.7698 - val_recall: 0.7638\n",
      "Epoch 44/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.2210 - precision: 0.9202 - recall: 0.9332 - val_accuracy: 0.7642 - val_loss: 0.6748 - val_precision: 0.7829 - val_recall: 0.7953\n",
      "Epoch 45/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.2168 - precision: 0.9075 - recall: 0.9332 - val_accuracy: 0.7511 - val_loss: 0.6726 - val_precision: 0.7652 - val_recall: 0.7953\n",
      "Epoch 46/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9103 - loss: 0.2149 - precision: 0.9104 - recall: 0.9251 - val_accuracy: 0.7642 - val_loss: 0.6628 - val_precision: 0.7920 - val_recall: 0.7795\n",
      "Epoch 47/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9147 - loss: 0.2051 - precision: 0.9062 - recall: 0.9393 - val_accuracy: 0.7598 - val_loss: 0.7416 - val_precision: 0.8103 - val_recall: 0.7402\n",
      "Epoch 48/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9125 - loss: 0.2094 - precision: 0.9157 - recall: 0.9231 - val_accuracy: 0.7467 - val_loss: 0.6981 - val_precision: 0.7674 - val_recall: 0.7795\n",
      "Epoch 49/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9223 - loss: 0.1983 - precision: 0.9155 - recall: 0.9433 - val_accuracy: 0.7642 - val_loss: 0.6863 - val_precision: 0.7920 - val_recall: 0.7795\n",
      "Epoch 50/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9234 - loss: 0.1951 - precision: 0.9240 - recall: 0.9352 - val_accuracy: 0.7380 - val_loss: 0.7159 - val_precision: 0.7724 - val_recall: 0.7480\n",
      "Test Accuracy: 0.7380\n",
      "Test Precision: 0.7724\n",
      "Test Recall: 0.7480\n",
      "Test F1 Score: 0.7600\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128,activation='relu',input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='tanh'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'Adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy', tf.keras.metrics.Precision(),tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test,y_test)\n",
    ")\n",
    "\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
